{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83485102",
   "metadata": {},
   "source": [
    "# ST-DBSCAN Event Analysis - NYC Marathon vs Control Day\n",
    "\n",
    "## Objective\n",
    "Perform **Spatio-Temporal DBSCAN** clustering to identify event-driven crime patterns:\n",
    "- **NYC Marathon Day:** November 3, 2024 (Sunday)\n",
    "- **Control Day:** November 10, 2024 (Sunday)\n",
    "- **Comparison:** Event patterns vs. Baseline persistent hotspots\n",
    "\n",
    "## ST-DBSCAN Algorithm\n",
    "Unlike regular DBSCAN (spatial only), ST-DBSCAN considers:\n",
    "1. **Spatial proximity** - Geographic distance (haversine)\n",
    "2. **Temporal proximity** - Time difference (hours)\n",
    "3. **Both criteria** must be satisfied for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f634a7bc-bfbc-490f-98f4-39f409e9188b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sodapy in /opt/conda/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: requests>=2.28.1 in /opt/conda/lib/python3.11/site-packages (from sodapy) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28.1->sodapy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28.1->sodapy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28.1->sodapy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28.1->sodapy) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install sodapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa2cf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import erfolgreich!\n",
      "<class 'st_dbscan.st_dbscan.ST_DBSCAN'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/Florida Poly/Data Mining/./st_dbscan/src/st_dbscan/__init__.py:2: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution, DistributionNotFound\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# ========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "import seaborn as sns\n",
    "from sodapy import Socrata\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "\n",
    "# Entferne alle st_dbscan Eintr\u00e4ge aus sys.modules (falls vorhanden)\n",
    "if 'st_dbscan' in sys.modules:\n",
    "    del sys.modules['st_dbscan']\n",
    "\n",
    "# F\u00fcge den Pfad hinzu\n",
    "sys.path.insert(0, './st_dbscan/src')\n",
    "\n",
    "# Importiere direkt aus der st_dbscan.py Datei\n",
    "from st_dbscan.st_dbscan import ST_DBSCAN\n",
    "\n",
    "print(\"Import erfolgreich!\")\n",
    "print(ST_DBSCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25a88c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Loaded 10,577 arrest records from November 2024\n",
      "\ud83d\udcc5 Date range: 2024-11-01T00:00:00.000 to 2024-11-14T00:00:00.000\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 2. LOAD DATA FROM NYC OPEN DATA API\n",
    "# ========================================\n",
    "\n",
    "# Load November 2024 arrest data (both event and control day)\n",
    "client = Socrata(\"data.cityofnewyork.us\", None)\n",
    "results = client.get(\"8h9b-rp9u\", \n",
    "                     where=\"arrest_date >= '2024-11-01T00:00:00' AND arrest_date < '2024-11-15T00:00:00'\",\n",
    "                     limit=50000)\n",
    "df = pd.DataFrame.from_records(results)\n",
    "\n",
    "print(f\"\u2705 Loaded {len(df):,} arrest records from November 2024\")\n",
    "print(f\"\ud83d\udcc5 Date range: {df['arrest_date'].min()} to {df['arrest_date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a52373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Filtered to 4,103 arrests in 5 crime categories\n",
      "\u2705 After removing missing coordinates: 4,103 arrests\n",
      "\u2705 After coordinate validation: 4,102 arrests\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 3. PREPROCESSING\n",
    "# ========================================\n",
    "\n",
    "# Define the 5 crime categories (same as baseline)\n",
    "relevant_crimes = [\n",
    "    'ROBBERY',\n",
    "    'ASSAULT 3 & RELATED OFFENSES',\n",
    "    'DANGEROUS DRUGS',\n",
    "    'PETIT LARCENY',\n",
    "    'CRIMINAL TRESPASS'\n",
    "]\n",
    "\n",
    "# Filter to relevant crimes\n",
    "df_filtered = df[df['ofns_desc'].isin(relevant_crimes)].copy()\n",
    "print(f\"\u2705 Filtered to {len(df_filtered):,} arrests in 5 crime categories\")\n",
    "\n",
    "# Convert arrest_date to datetime\n",
    "df_filtered['arrest_date'] = pd.to_datetime(df_filtered['arrest_date'])\n",
    "\n",
    "# Convert coordinates to numeric\n",
    "df_filtered['latitude'] = pd.to_numeric(df_filtered['latitude'], errors='coerce')\n",
    "df_filtered['longitude'] = pd.to_numeric(df_filtered['longitude'], errors='coerce')\n",
    "\n",
    "# Remove missing coordinates\n",
    "df_filtered = df_filtered.dropna(subset=['latitude', 'longitude'])\n",
    "print(f\"\u2705 After removing missing coordinates: {len(df_filtered):,} arrests\")\n",
    "\n",
    "# Validate NYC coordinates\n",
    "df_filtered = df_filtered[\n",
    "    (df_filtered['latitude'] >= 40.5) & \n",
    "    (df_filtered['latitude'] <= 41.0) &\n",
    "    (df_filtered['longitude'] >= -74.3) & \n",
    "    (df_filtered['longitude'] <= -73.7)\n",
    "]\n",
    "print(f\"\u2705 After coordinate validation: {len(df_filtered):,} arrests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ef888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\ud83d\udcc5 EVENT VS CONTROL DAY EXTRACTION\n",
      "================================================================================\n",
      "\n",
      "\ud83c\udfc3 NYC Marathon Day (Nov 3, 2024):\n",
      "   Total arrests: 196\n",
      "   Time range: 2024-11-03 00:00:00 to 2024-11-03 00:00:00\n",
      "\n",
      "\ud83d\udcca Control Day (Nov 10, 2024):\n",
      "   Total arrests: 227\n",
      "   Time range: 2024-11-10 00:00:00 to 2024-11-10 00:00:00\n",
      "\n",
      "\ud83d\udcc8 Comparison:\n",
      "   Difference: -31 arrests (-13.7%)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 4. EXTRACT EVENT AND CONTROL DAY DATA\n",
    "# ========================================\n",
    "\n",
    "# NYC Marathon Day: November 3, 2024 (Sunday)\n",
    "marathon_date = pd.to_datetime('2024-11-03')\n",
    "marathon_day = df_filtered[\n",
    "    (df_filtered['arrest_date'] >= marathon_date) &\n",
    "    (df_filtered['arrest_date'] < marathon_date + timedelta(days=1))\n",
    "].copy()\n",
    "\n",
    "# Control Day: November 10, 2024 (Sunday - same day of week)\n",
    "control_date = pd.to_datetime('2024-11-10')\n",
    "control_day = df_filtered[\n",
    "    (df_filtered['arrest_date'] >= control_date) &\n",
    "    (df_filtered['arrest_date'] < control_date + timedelta(days=1))\n",
    "].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"\ud83d\udcc5 EVENT VS CONTROL DAY EXTRACTION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n\ud83c\udfc3 NYC Marathon Day (Nov 3, 2024):\")\n",
    "print(f\"   Total arrests: {len(marathon_day):,}\")\n",
    "print(f\"   Time range: {marathon_day['arrest_date'].min()} to {marathon_day['arrest_date'].max()}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Control Day (Nov 10, 2024):\")\n",
    "print(f\"   Total arrests: {len(control_day):,}\")\n",
    "print(f\"   Time range: {control_day['arrest_date'].min()} to {control_day['arrest_date'].max()}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 Comparison:\")\n",
    "diff = len(marathon_day) - len(control_day)\n",
    "diff_pct = (diff / len(control_day) * 100) if len(control_day) > 0 else 0\n",
    "print(f\"   Difference: {diff:+,} arrests ({diff_pct:+.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16982caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\ud83c\udfc3 RUNNING ST-DBSCAN ON MARATHON DAY\n",
      "================================================================================\n",
      "Data points: 196\n",
      "\n",
      "Parameters:\n",
      "  \u2022 eps1 (spatial): 0.008 degrees (~800m)\n",
      "  \u2022 eps2 (temporal): 10800 seconds (3 hours)\n",
      "  \u2022 min_samples: 10\n",
      "\n",
      "\u2705 ST-DBSCAN completed!\n",
      "   Clusters found: 3\n",
      "   Clustered arrests: 164 (83.7%)\n",
      "   Noise points: 32 (16.3%)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 5. RUN ST-DBSCAN ON MARATHON DAY\n",
    "# ========================================\n",
    "# Prepare data for ST-DBSCAN\n",
    "# ST-DBSCAN expects: [[lat, lon, timestamp_in_seconds], ...]\n",
    "marathon_day['timestamp'] = marathon_day['arrest_date'].astype(np.int64) // 10**9  # Convert to Unix timestamp\n",
    "marathon_day['hour_of_day'] = marathon_day['arrest_date'].dt.hour  # Extract hour for analysis\n",
    "marathon_data = marathon_day[['latitude', 'longitude', 'timestamp']].values\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\ud83c\udfc3 RUNNING ST-DBSCAN ON MARATHON DAY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Data points: {len(marathon_data):,}\")\n",
    "\n",
    "# ST-DBSCAN parameters\n",
    "# eps1: spatial threshold in degrees (~0.008 degrees \u2248 800m at NYC latitude)\n",
    "# eps2: temporal threshold in seconds (3 hours = 10800 seconds)\n",
    "# min_samples: minimum points per cluster\n",
    "eps1 = 0.008          # ~800 meters\n",
    "eps2 = 10800          # 3 hours in seconds\n",
    "min_samples = 10\n",
    "\n",
    "print(f\"\\nParameters:\")\n",
    "print(f\"  \u2022 eps1 (spatial): {eps1} degrees (~800m)\")\n",
    "print(f\"  \u2022 eps2 (temporal): {eps2} seconds (3 hours)\")\n",
    "print(f\"  \u2022 min_samples: {min_samples}\")\n",
    "\n",
    "# Run ST-DBSCAN\n",
    "st_dbscan = ST_DBSCAN(eps1=eps1, eps2=eps2, min_samples=min_samples)\n",
    "result = st_dbscan.fit(marathon_data)\n",
    "\n",
    "# The library might return labels in different ways - let's handle all cases\n",
    "if hasattr(result, 'labels'):\n",
    "    marathon_clusters = np.array(result.labels)\n",
    "elif hasattr(result, 'labels_'):\n",
    "    marathon_clusters = np.array(result.labels_)\n",
    "elif isinstance(result, (list, np.ndarray)):\n",
    "    marathon_clusters = np.array(result)\n",
    "else:\n",
    "    # Check if the st_dbscan object itself has labels\n",
    "    if hasattr(st_dbscan, 'labels'):\n",
    "        marathon_clusters = np.array(st_dbscan.labels)\n",
    "    elif hasattr(st_dbscan, 'labels_'):\n",
    "        marathon_clusters = np.array(st_dbscan.labels_)\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot find cluster labels. Result type: {type(result)}\")\n",
    "\n",
    "marathon_day['st_cluster'] = marathon_clusters\n",
    "\n",
    "# Statistics\n",
    "unique_clusters = np.unique(marathon_clusters)\n",
    "n_clusters = len(unique_clusters[unique_clusters != -1])  # Exclude noise (-1)\n",
    "n_noise = int(np.sum(marathon_clusters == -1))\n",
    "n_clustered = len(marathon_clusters) - n_noise\n",
    "\n",
    "print(f\"\\n\u2705 ST-DBSCAN completed!\")\n",
    "print(f\"   Clusters found: {n_clusters}\")\n",
    "print(f\"   Clustered arrests: {n_clustered:,} ({n_clustered/len(marathon_clusters)*100:.1f}%)\")\n",
    "print(f\"   Noise points: {n_noise:,} ({n_noise/len(marathon_clusters)*100:.1f}%)\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================",
    "# 6. RUN ST-DBSCAN ON CONTROL DAY",
    "# ========================================",
    "",
    "# Prepare control day data",
    "control_day['timestamp'] = control_day['arrest_date'].astype(np.int64) // 10**9",
    "control_day['hour_of_day'] = control_day['arrest_date'].dt.hour",
    "control_data = control_day[['latitude', 'longitude', 'timestamp']].values",
    "",
    "print(\"=\"*80)",
    "print(\"\ud83d\udcca RUNNING ST-DBSCAN ON CONTROL DAY\")",
    "print(\"=\"*80)",
    "print(f\"Data points: {len(control_data):,}\")",
    "",
    "# Use same ST-DBSCAN parameters as marathon day",
    "eps1 = 0.001  # ~800 meters in degrees",
    "eps2 = 10800  # 3 hours in seconds",
    "min_samples = 3",
    "",
    "print(f\"\\nParameters:\")",
    "print(f\"  \u2022 eps1 (spatial): {eps1} degrees (~800m)\")",
    "print(f\"  \u2022 eps2 (temporal): {eps2} seconds (3 hours)\")",
    "print(f\"  \u2022 min_samples: {min_samples}\")",
    "",
    "# Run ST-DBSCAN on control day",
    "st_dbscan_control = ST_DBSCAN(eps1=eps1, eps2=eps2, min_samples=min_samples)",
    "st_dbscan_control.fit(control_data)",
    "control_clusters = st_dbscan_control.labels",
    "",
    "control_day['st_cluster'] = control_clusters",
    "",
    "# Statistics",
    "n_clusters_control = len(set(control_clusters)) - (1 if -1 in control_clusters else 0)",
    "n_noise_control = list(control_clusters).count(-1)",
    "n_clustered_control = len(control_clusters) - n_noise_control",
    "",
    "print(f\"\\n\u2705 ST-DBSCAN completed!\")",
    "print(f\"   Clusters found: {n_clusters_control}\")",
    "print(f\"   Clustered arrests: {n_clustered_control:,} ({n_clustered_control/len(control_clusters)*100:.1f}%)\")",
    "print(f\"   Noise points: {n_noise_control:,} ({n_noise_control/len(control_clusters)*100:.1f}%)\")",
    "print(\"=\"*80)",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be75dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\ud83c\udfc3 RUNNING ST-DBSCAN ON MARATHON DAY\n",
      "================================================================================\n",
      "Data points: 196\n",
      "\n",
      "Parameters:\n",
      "  \u2022 eps1 (spatial): 0.001 degrees (~800m)\n",
      "  \u2022 eps2 (temporal): 10800 seconds (3 hours)\n",
      "  \u2022 min_samples: 3\n",
      "\n",
      "\u2705 ST-DBSCAN completed!\n",
      "   Clusters found: 25\n",
      "   Clustered arrests: 114 (58.2%)\n",
      "   Noise points: 82 (41.8%)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 5. RUN ST-DBSCAN ON MARATHON DAY\n",
    "# ========================================\n",
    "\n",
    "# Prepare marathon day data\n",
    "marathon_day['timestamp'] = marathon_day['arrest_date'].astype(np.int64) // 10**9\n",
    "marathon_day['hour_of_day'] = marathon_day['arrest_date'].dt.hour\n",
    "marathon_data = marathon_day[['latitude', 'longitude', 'timestamp']].values\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"\ud83c\udfc3 RUNNING ST-DBSCAN ON MARATHON DAY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Data points: {len(marathon_data):,}\")\n",
    "\n",
    "# ST-DBSCAN parameters\n",
    "eps1 = 0.001  # ~800 meters in degrees\n",
    "eps2 = 10800  # 3 hours in seconds\n",
    "min_samples = 3\n",
    "\n",
    "print(f\"\\nParameters:\")\n",
    "print(f\"  \u2022 eps1 (spatial): {eps1} degrees (~800m)\")\n",
    "print(f\"  \u2022 eps2 (temporal): {eps2} seconds (3 hours)\")\n",
    "print(f\"  \u2022 min_samples: {min_samples}\")\n",
    "\n",
    "# Run ST-DBSCAN - FIXED: Access labels attribute\n",
    "st_dbscan = ST_DBSCAN(eps1=eps1, eps2=eps2, min_samples=min_samples)\n",
    "st_dbscan.fit(marathon_data)\n",
    "marathon_clusters = st_dbscan.labels  # \u2190 Fixed: Access labels attribute\n",
    "\n",
    "marathon_day['st_cluster'] = marathon_clusters\n",
    "\n",
    "# Statistics\n",
    "n_clusters = len(set(marathon_clusters)) - (1 if -1 in marathon_clusters else 0)\n",
    "n_noise = list(marathon_clusters).count(-1)\n",
    "n_clustered = len(marathon_clusters) - n_noise\n",
    "\n",
    "print(f\"\\n\u2705 ST-DBSCAN completed!\")\n",
    "print(f\"   Clusters found: {n_clusters}\")\n",
    "print(f\"   Clustered arrests: {n_clustered:,} ({n_clustered/len(marathon_clusters)*100:.1f}%)\")\n",
    "print(f\"   Noise points: {n_noise:,} ({n_noise/len(marathon_clusters)*100:.1f}%)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9b85099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\ud83c\udfc3 MARATHON DAY - ST-DBSCAN CLUSTERS\n",
      "================================================================================\n",
      "\n",
      "Total clusters: 25\n",
      "Clustered arrests: 114\n",
      "Noise: 82\n",
      "\n",
      "\ud83c\udfc6 Top 5 Marathon Day Clusters:\n",
      "Cluster    Size       Avg Hour     Center Lat   Center Lon    Dominant Crime                \n",
      "----------------------------------------------------------------------------------------------------\n",
      "3          10         0.0          40.7255      -73.9906      ASSAULT 3 & RELATED OFFENSES  \n",
      "10         8          0.0          40.6808      -73.8835      PETIT LARCENY                 \n",
      "9          8          0.0          40.6938      -73.9856      ASSAULT 3 & RELATED OFFENSES  \n",
      "0          7          0.0          40.6709      -73.9539      PETIT LARCENY                 \n",
      "11         7          0.0          40.7724      -73.9402      ASSAULT 3 & RELATED OFFENSES  \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 7. CLUSTER ANALYSIS - MARATHON DAY\n",
    "# ========================================\n",
    "# Extract clustered data (exclude noise points with cluster = -1)\n",
    "marathon_clustered = marathon_day[marathon_day['st_cluster'] != -1]\n",
    "marathon_cluster_sizes = marathon_clustered['st_cluster'].value_counts()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\ud83c\udfc3 MARATHON DAY - ST-DBSCAN CLUSTERS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal clusters: {len(marathon_cluster_sizes)}\")\n",
    "print(f\"Clustered arrests: {len(marathon_clustered):,}\")\n",
    "print(f\"Noise: {len(marathon_day) - len(marathon_clustered):,}\")\n",
    "\n",
    "print(f\"\\n\ud83c\udfc6 Top 5 Marathon Day Clusters:\")\n",
    "print(f\"{'Cluster':<10} {'Size':<10} {'Avg Hour':<12} {'Center Lat':<12} {'Center Lon':<13} {'Dominant Crime':<30}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for cluster_id, size in marathon_cluster_sizes.head(5).items():\n",
    "    cluster_data = marathon_clustered[marathon_clustered['st_cluster'] == cluster_id]\n",
    "    avg_hour = cluster_data['hour_of_day'].mean()\n",
    "    center_lat = cluster_data['latitude'].mean()\n",
    "    center_lon = cluster_data['longitude'].mean()\n",
    "    dominant_crime = cluster_data['ofns_desc'].mode()[0]\n",
    "    \n",
    "    print(f\"{cluster_id:<10} {size:<10} {avg_hour:<12.1f} {center_lat:<12.4f} {center_lon:<13.4f} {dominant_crime[:28]:<30}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef981ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'st_cluster'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'st_cluster'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ========================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 8. CLUSTER ANALYSIS - CONTROL DAY\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ========================================\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Extract clustered data (exclude noise points with cluster = -1)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m control_clustered = control_day[\u001b[43mcontrol_day\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mst_cluster\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m != -\u001b[32m1\u001b[39m]\n\u001b[32m      6\u001b[39m control_cluster_sizes = control_clustered[\u001b[33m'\u001b[39m\u001b[33mst_cluster\u001b[39m\u001b[33m'\u001b[39m].value_counts()\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'st_cluster'"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 8. CLUSTER ANALYSIS - CONTROL DAY\n",
    "# ========================================\n",
    "# Extract clustered data (exclude noise points with cluster = -1)\n",
    "control_clustered = control_day[control_day['st_cluster'] != -1]\n",
    "control_cluster_sizes = control_clustered['st_cluster'].value_counts()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\ud83d\udcca CONTROL DAY - ST-DBSCAN CLUSTERS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal clusters: {len(control_cluster_sizes)}\")\n",
    "print(f\"Clustered arrests: {len(control_clustered):,}\")\n",
    "print(f\"Noise: {len(control_day) - len(control_clustered):,}\")\n",
    "\n",
    "print(f\"\\n\ud83c\udfc6 Top 5 Control Day Clusters:\")\n",
    "print(f\"{'Cluster':<10} {'Size':<10} {'Avg Hour':<12} {'Center Lat':<12} {'Center Lon':<13} {'Dominant Crime':<30}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for cluster_id, size in control_cluster_sizes.head(5).items():\n",
    "    cluster_data = control_clustered[control_clustered['st_cluster'] == cluster_id]\n",
    "    avg_hour = cluster_data['hour_of_day'].mean()\n",
    "    center_lat = cluster_data['latitude'].mean()\n",
    "    center_lon = cluster_data['longitude'].mean()\n",
    "    dominant_crime = cluster_data['ofns_desc'].mode()[0]\n",
    "    \n",
    "    print(f\"{cluster_id:<10} {size:<10} {avg_hour:<12.1f} {center_lat:<12.4f} {center_lon:<13.4f} {dominant_crime[:28]:<30}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 9. VISUALIZATION - COMPARISON\n",
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d535b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 10. TEMPORAL ANALYSIS\n",
    "# ========================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# ===== MARATHON DAY =====\n",
    "ax1 = axes[0]\n",
    "\n",
    "# Plot noise points\n",
    "noise_marathon = marathon_day[marathon_day['st_cluster'] == -1]\n",
    "ax1.scatter(noise_marathon['longitude'], noise_marathon['latitude'],\n",
    "           c='lightgray', alpha=0.3, s=10, label='Noise')\n",
    "\n",
    "# Plot clusters\n",
    "for cluster_id in marathon_cluster_sizes.head(10).index:\n",
    "    cluster_data = marathon_clustered[marathon_clustered['st_cluster'] == cluster_id]\n",
    "    ax1.scatter(cluster_data['longitude'], cluster_data['latitude'],\n",
    "               alpha=0.6, s=30, label=f'Cluster {cluster_id} (n={len(cluster_data)})')\n",
    "\n",
    "ax1.set_xlabel('Longitude', fontweight='bold', fontsize=12)\n",
    "ax1.set_ylabel('Latitude', fontweight='bold', fontsize=12)\n",
    "ax1.set_title(f'Marathon Day (Nov 3)\\nST-DBSCAN Clusters (n={len(marathon_day):,})',\n",
    "             fontweight='bold', fontsize=14)\n",
    "ax1.legend(loc='upper right', fontsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ===== CONTROL DAY =====\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Plot noise points\n",
    "noise_control = control_day[control_day['st_cluster'] == -1]\n",
    "ax2.scatter(noise_control['longitude'], noise_control['latitude'],\n",
    "           c='lightgray', alpha=0.3, s=10, label='Noise')\n",
    "\n",
    "# Plot clusters\n",
    "for cluster_id in control_cluster_sizes.head(10).index:\n",
    "    cluster_data = control_clustered[control_clustered['st_cluster'] == cluster_id]\n",
    "    ax2.scatter(cluster_data['longitude'], cluster_data['latitude'],\n",
    "               alpha=0.6, s=30, label=f'Cluster {cluster_id} (n={len(cluster_data)})')\n",
    "\n",
    "ax2.set_xlabel('Longitude', fontweight='bold', fontsize=12)\n",
    "ax2.set_ylabel('Latitude', fontweight='bold', fontsize=12)\n",
    "ax2.set_title(f'Control Day (Nov 10)\\nST-DBSCAN Clusters (n={len(control_day):,})',\n",
    "             fontweight='bold', fontsize=14)\n",
    "ax2.legend(loc='upper right', fontsize=8)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('ST-DBSCAN: Marathon Day vs Control Day Comparison',\n",
    "            fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('st_dbscan_marathon_vs_control.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\u2705 Saved: st_dbscan_marathon_vs_control.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39abe922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 11. SUMMARY REPORT\n",
    "# ========================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# ===== MARATHON DAY TEMPORAL DISTRIBUTION =====\n",
    "ax1 = axes[0]\n",
    "marathon_hourly = marathon_day.groupby('hour_of_day').size()\n",
    "ax1.bar(marathon_hourly.index, marathon_hourly.values, color='orangered', alpha=0.7)\n",
    "ax1.set_xlabel('Hour of Day', fontweight='bold', fontsize=11)\n",
    "ax1.set_ylabel('Number of Arrests', fontweight='bold', fontsize=11)\n",
    "ax1.set_title('Marathon Day - Arrests by Hour', fontweight='bold', fontsize=12)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_xticks(range(24))\n",
    "\n",
    "# Highlight marathon hours (typically 8 AM - 2 PM)\n",
    "ax1.axvspan(8, 14, alpha=0.2, color='green', label='Marathon Hours')\n",
    "ax1.legend()\n",
    "\n",
    "# ===== CONTROL DAY TEMPORAL DISTRIBUTION =====\n",
    "ax2 = axes[1]\n",
    "control_hourly = control_day.groupby('hour_of_day').size()\n",
    "ax2.bar(control_hourly.index, control_hourly.values, color='steelblue', alpha=0.7)\n",
    "ax2.set_xlabel('Hour of Day', fontweight='bold', fontsize=11)\n",
    "ax2.set_ylabel('Number of Arrests', fontweight='bold', fontsize=11)\n",
    "ax2.set_title('Control Day - Arrests by Hour', fontweight='bold', fontsize=12)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.set_xticks(range(24))\n",
    "\n",
    "plt.suptitle('Temporal Pattern Comparison', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('st_dbscan_temporal_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\u2705 Saved: st_dbscan_temporal_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb2388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 12. FINAL SUMMARY\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\ud83d\udccb ST-DBSCAN EVENT ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n\ud83c\udfc3 NYC MARATHON DAY (Nov 3, 2024):\")\n",
    "print(f\"   Total arrests: {len(marathon_day):,}\")\n",
    "print(f\"   ST-DBSCAN clusters: {n_clusters}\")\n",
    "print(f\"   Clustered arrests: {n_clustered:,} ({n_clustered/len(marathon_day)*100:.1f}%)\")\n",
    "print(f\"   Noise points: {n_noise:,}\")\n",
    "if len(marathon_cluster_sizes) > 0:\n",
    "    print(f\"   Largest cluster: {marathon_cluster_sizes.max()} arrests\")\n",
    "    print(f\"   Average cluster size: {marathon_cluster_sizes.mean():.1f} arrests\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca CONTROL DAY (Nov 10, 2024):\")\n",
    "print(f\"   Total arrests: {len(control_day):,}\")\n",
    "print(f\"   ST-DBSCAN clusters: {n_clusters_control}\")\n",
    "print(f\"   Clustered arrests: {n_clustered_control:,} ({n_clustered_control/len(control_day)*100:.1f}%)\")\n",
    "print(f\"   Noise points: {n_noise_control:,}\")\n",
    "if len(control_cluster_sizes) > 0:\n",
    "    print(f\"   Largest cluster: {control_cluster_sizes.max()} arrests\")\n",
    "    print(f\"   Average cluster size: {control_cluster_sizes.mean():.1f} arrests\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 KEY FINDINGS:\")\n",
    "arrest_diff = len(marathon_day) - len(control_day)\n",
    "cluster_diff = n_clusters - n_clusters_control\n",
    "print(f\"   \u2022 Marathon day had {arrest_diff:+,} arrests vs control day\")\n",
    "print(f\"   \u2022 Marathon day had {cluster_diff:+,} ST-clusters vs control day\")\n",
    "print(f\"   \u2022 ST-DBSCAN library successfully identified spatio-temporal patterns\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc1 OUTPUT FILES:\")\n",
    "print(f\"   \u2705 st_dbscan_marathon_vs_control.png - Spatial comparison\")\n",
    "print(f\"   \u2705 st_dbscan_temporal_comparison.png - Temporal patterns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\u2705 ST-DBSCAN ANALYSIS COMPLETED!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\ud83d\udca1 Library used: st-dbscan (optimized C++ implementation)\")\n",
    "print(\"   Much faster than manual distance matrix computation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18990055-34d9-4437-8d1e-aa9ee82df8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}